{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc57700-e185-429d-a12d-0374f81bfa74",
   "metadata": {
    "metadata": {},
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ec996-12f5-43b1-a70e-911828459e7e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imghdr\n",
    "import os\n",
    "\n",
    "data_dir = \"/hair_types\"\n",
    "image_extensions = [\".png\", \".jpg\", \"\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "            os.remove(filepath)\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")\n",
    "            os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f9988-6483-40ca-a177-7505f397f8a0",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "directory = \"hair_types\"\n",
    "file_count = sum(len(files) for _, _, files in os.walk(directory))\n",
    "\n",
    "print(f\"Total number of files in the directory: {file_count}\")\n",
    "\n",
    "\n",
    "image_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"hair_types/\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"hair_types/\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size, \n",
    "    labels='inferred',\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7118977-653c-40a7-ac4f-85c4f8e02315",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(np.argmax(labels[i])))\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad576a6-17ae-4ef4-82b0-2ac22a9c4003",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.Input(shape=image_size + (3,)))\n",
    "model.add(layers.Rescaling(1.0 / 255))\n",
    "model.add(layers.RandomFlip(\"horizontal\"))\n",
    "model.add(layers.RandomRotation(0.1))\n",
    "\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=7, strides=(1,1), padding='valid', dilation_rate=1, kernel_regularizer=keras.regularizers.l2(1e-05), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.1))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(filters=192, kernel_size=5, strides=(1,1), padding='valid', dilation_rate=1, kernel_regularizer=keras.regularizers.l2(1e-05), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.1))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=3, strides=(1,1), padding='valid', dilation_rate=2, kernel_regularizer=keras.regularizers.l2(1e-05), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.1))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(100, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())  # Added Batch Normalization\n",
    "model.add(layers.Dropout(0.3))  # Uncommented and adjusted Dropout\n",
    "\n",
    "model.add(layers.Dense(50, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())  # Added Batch Normalization before activation\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.Dropout(0.3))  # Uncommented and adjusted Dropout\n",
    "\n",
    "\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "#tf.keras.utils.plot_model(model, to_file='model_test.png', show_shapes=True)\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.1),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f39a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "#model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[early_stopping])\n",
    "\n",
    "# Assuming train_ds and val_ds are defined and the model is compiled\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[early_stopping])\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
    "\n",
    "# Plot the training and validation loss\n",
    "ax1.plot(history.history['loss'], label='Training Loss')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Show the combined graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbbca4-5313-48e7-b8f1-1af77c6b160a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    \"hair_types/Curly_Hair/02dac897d1dec9ba8c057a11d041ada8--layered-natural-hair-natural-black-hairstyles.jpg\", target_size=image_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(\n",
    "    \"This image is %.2f percent curly hair, %.2f percent straight hair, and %.2f percent wavy hair.\"\n",
    "    % tuple(predictions[0])\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
